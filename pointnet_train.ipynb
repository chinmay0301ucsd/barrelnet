{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pointnet_utils import PointNetEncoder, feature_transform_reguliarzer\n",
    "\n",
    "\n",
    "## Write a Dataset Class to generate Cylinder Dataset, with different poses and augmentations. \n",
    "\n",
    "\n",
    "\n",
    "class BarrelNet(nn.Module):\n",
    "    def __init__(self, k=40, normal_channel=True):\n",
    "        super(BarrelNet, self).__init__()\n",
    "        if normal_channel:\n",
    "            channel = 6\n",
    "        else:\n",
    "            channel = 3\n",
    "        self.feat_normal = PointNetEncoder(global_feat=True, use_Tnet=False, channel=channel)\n",
    "        self.feat_radius = PointNetEncoder(global_feat=True, use_Tnet=True, channel=channel)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xn, _, _ = self.feat_normal(x)\n",
    "        xr, _, _ = self.feat_radius(x)\n",
    "        x = (xn + xr)/2# in future make it (xn + xr)/2\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        radius = F.sigmoid(x[:,-1])        \n",
    "        normal = torch.concatenate([F.tanh(x[:,:2]), F.sigmoid(x[:,2:3])], dim=1)\n",
    "        normal = normal / torch.linalg.norm(normal, dim=-1, keepdim=True)\n",
    "        return radius, normal \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "def create_capped_cylinder(radius, height, sections=32):\n",
    "    \"\"\"\n",
    "    Create a capped cylinder using trimesh.\n",
    "    \n",
    "    Args:\n",
    "        radius (float): Radius of the cylinder.\n",
    "        height (float): Height of the cylinder.\n",
    "        sections (int): Number of sections for the cylinder's roundness.\n",
    "        \n",
    "    Returns:\n",
    "        trimesh.Trimesh: A capped cylinder mesh.\n",
    "    \"\"\"\n",
    "    # Create the capped cylinder with cap=True\n",
    "    capped_cylinder = trimesh.creation.cylinder(radius=radius, height=height, sections=sections, cap=True)\n",
    "    \n",
    "    return capped_cylinder\n",
    "\n",
    "# Example usage\n",
    "radius = 1.0\n",
    "height = 4.0\n",
    "capped_cylinder = create_capped_cylinder(radius, height)\n",
    "\n",
    "# Visualization (optional)\n",
    "capped_cylinder.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import roma\n",
    "from data import generate_cylinder_pts, prepare_point_cloud, normalize_pc, CylinderData\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "    \n",
    "train_data = CylinderData(num_poses=5000)\n",
    "test_data = CylinderData(num_poses=1000)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "pointnet = BarrelNet(k=4, normal_channel=False).cuda()\n",
    "pointnet.train()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(pointnet.parameters(), lr=0.00005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.9)\n",
    "\n",
    "def compute_loss(sample, radius_pred, axis_pred, use_radius_loss=False, use_axis_loss=True):\n",
    "    \"\"\" Compute loss on the predictions of pointnet \"\"\"\n",
    "    assert use_axis_loss or use_radius_loss, \"Atleast one of the losses should be used\"\n",
    "    loss_axis = (1 - F.cosine_similarity(sample['axis_vec'], axis_pred, dim=1)).mean()\n",
    "    loss_radius = F.mse_loss(radius_pred, sample['radius_gt'] / sample['scale_gt'])\n",
    "    loss = 0.0 \n",
    "    if use_radius_loss:\n",
    "        loss = loss + loss_radius\n",
    "    if use_axis_loss:\n",
    "        loss = loss + loss_axis\n",
    "    return loss\n",
    "\n",
    "def train(model, train_loader, optimizer, scheduler, num_epochs=10000, save_epoch=1000, save_dir='weights/r0'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for sample in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            radius_pred, axis_pred = model(sample['pts'])\n",
    "            loss = compute_loss(sample, radius_pred, axis_pred, use_radius_loss=False, use_axis_loss=True)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Step the scheduler at the end of each epoch\n",
    "        scheduler.step()\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}, LR: {scheduler.get_last_lr()[0]}')\n",
    "\n",
    "        if epoch % save_epoch == 0:\n",
    "            torch.save(pointnet.state_dict(), os.path.join(save_dir, f'pointnet_iter{epoch}.pth'))\n",
    "\n",
    "train(pointnet, train_loader, optimizer, scheduler)\n",
    "torch.save(pointnet.state_dict(), 'weights/pointnet.pth')\n",
    "\n",
    "# # Example usage\n",
    "\n",
    "# points = generate_cylinder_pts(1.0, 1.0)\n",
    "# axis = torch.tensor([0.0, 0.0, 1.0])\n",
    "# points_valid, radius, burial_offset = prepare_point_cloud(points, axis)\n",
    "# pts, scale = normalize_pc(points_valid)\n",
    "# point_cloud_np = points.cpu().numpy()\n",
    "# point_cloud_rotated_np = points_valid.cpu().numpy()\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(121, projection='3d')\n",
    "# ax1.scatter(point_cloud_np[:, 0], point_cloud_np[:, 1], point_cloud_np[:, 2], s=1)\n",
    "# ax1.set_title(\"Original Point Cloud\")\n",
    "\n",
    "# ax2 = fig.add_subplot(122, projection='3d')\n",
    "# ax2.scatter(point_cloud_rotated_np[:, 0], point_cloud_rotated_np[:, 1], point_cloud_rotated_np[:, 2], s=1)\n",
    "# ax2.set_title(\"Rotated Point Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    running_acc_axis = 0.0\n",
    "    accs_axis = []\n",
    "    criterion_cosine = nn.CosineSimilarity(dim=1)\n",
    "    for sample in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            radius_pred, axis_pred = model(sample['pts'])\n",
    "            radius_pred = radius_pred * sample['scale_gt'].cuda()\n",
    "            acc_axis = (1 + criterion_cosine(sample['axis_vec'], axis_pred).mean())/2\n",
    "            running_acc_axis += acc_axis.item()\n",
    "            accs_axis.append(acc_axis)\n",
    "    accs = torch.tensor(accs_axis)\n",
    "    print(f\"Best Accuracy: {torch.max(accs)}\")\n",
    "    print(f\"Worst Accuracy: {torch.min(accs)}\")\n",
    "    print(f'Average Accuracy: {running_acc_axis / len(test_loader)}')\n",
    "\n",
    "\n",
    "test(pointnet, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDepthIntegrator(mi.SamplingIntegrator):\n",
    "    def __init__(self, props):\n",
    "        super().__init__(props)\n",
    "\n",
    "    def sample(self, scene, sampler, ray, medium, aovs, active=True):\n",
    "        si = scene.ray_intersect(ray, active=True)\n",
    "        depth = mi.Float(10000.0)  # Large value for depth background\n",
    "        depth = mi.select(si.is_valid(), si.t, depth)\n",
    "        return mi.Spectrum(depth), active\n",
    "    \n",
    "mi.register_integrator('custom_depth', lambda props: CustomDepthIntegrator(props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating partially occluded point cloud. \n",
    "import mitsuba as mi\n",
    "import numpy as np \n",
    "import roma\n",
    "import torch\n",
    "import drjit as dr\n",
    "from matplotlib import pyplot as plt\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
    "\n",
    "mi.set_variant('cuda_ad_rgb')\n",
    "import trimesh \n",
    "\n",
    "def rotate_to_axis(axis, device='cuda'):\n",
    "    \"\"\"\n",
    "    Rotate the point cloud to align its z-axis with the given axis using PyTorch.\n",
    "    \n",
    "    Args:\n",
    "        axis (torch.Tensor): Target axis to align with, should be of shape (3,).\n",
    "        device (str): Device to perform the computation ('cpu' or 'cuda').\n",
    "    Returns:\n",
    "        torch.Tensor: Rotated point cloud of shape (N, 3).\n",
    "    \"\"\"\n",
    "    ## TODO: make this batched, to rotate the point cloud to different configurations at once. \n",
    "    # Normalize the axis\n",
    "    axis = axis / torch.linalg.norm(axis)\n",
    "    z_axis = torch.tensor([0., 0., 1.], device='cuda')\n",
    "    rotation_vector = torch.cross(z_axis, axis)\n",
    "    angle = torch.arccos(torch.dot(z_axis, axis))\n",
    "    \n",
    "    # Convert rotation vector and angle to a PyTorch tensor\n",
    "    rotation_vector = torch.tensor(rotation_vector, dtype=torch.float32, device=device)\n",
    "    angle = torch.tensor(angle, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Create the rotation matrix using torch-roma\n",
    "    rotation_matrix = roma.rotvec_to_rotmat(rotation_vector * angle)\n",
    "    return rotation_matrix\n",
    "    \n",
    "    \n",
    "\n",
    "## load cylinder mesh in mitsuba 3 \n",
    "burial_offset = 0.0\n",
    "capped_cylinder = trimesh.creation.cylinder(radius=1.0, height=2.5, sections=64, cap=True)\n",
    "axis = torch.tensor([0.,0.,1.0]).cuda()\n",
    "rotmat = rotate_to_axis(axis).cpu().numpy()\n",
    "pose = np.eye(4)\n",
    "pose[:3,:3] = rotmat\n",
    "pose[2,3] = burial_offset\n",
    "capped_cylinder.apply_transform(pose)\n",
    "\n",
    "def get_mi_mesh(_name, _vertex_positions, _triangle_indices, _id):\n",
    "\t\n",
    "\tvertex_pos = mi.TensorXf(_vertex_positions)\n",
    "\tface_indices = mi.TensorXu(_triangle_indices)\n",
    "\tprops = mi.Properties()\n",
    "\tbsdf = mi.load_dict({\n",
    "\t\t'type': 'diffuse',\n",
    "\t\t'reflectance': {\n",
    "\t\t\t'type': 'rgb',\n",
    "\t\t\t'value': [1, 0, 0]\n",
    "\t\t\t}\n",
    "\t\t})\n",
    "\temitter = mi.load_dict({\n",
    "\t\t'type': 'area',\n",
    "\t\t'radiance': {\n",
    "\t\t\t'type': 'rgb',\n",
    "\t\t\t'value': [1, 0, 0],\n",
    "\t\t\t}\n",
    "\t\t})\n",
    "\tprops[\"mesh_bsdf\"] = bsdf\n",
    "\n",
    "\tmesh = mi.Mesh(\n",
    "\t\t_name,\n",
    "\t\tvertex_count=_vertex_positions.shape[0],\n",
    "\t\tface_count=_triangle_indices.shape[0],\n",
    "\t\thas_vertex_normals=False,\n",
    "\t\thas_vertex_texcoords=False,\n",
    "\t\tprops=props\n",
    "\t)\n",
    "\tmesh_params = mi.traverse(mesh)\n",
    "\tmesh_params[\"vertex_positions\"] = dr.ravel(vertex_pos)\n",
    "\tmesh_params[\"faces\"] = dr.ravel(face_indices)\n",
    "\tmesh_params.update()\n",
    "\treturn mesh \n",
    "\n",
    "mesh = get_mi_mesh(\"cylinder\", capped_cylinder.vertices, capped_cylinder.faces, 0)\n",
    "scene = mi.load_dict({\n",
    "    \"type\": \"scene\",\n",
    "    \"integrator\": {\"type\": \"aov\", \"aovs\": 'dd.y::depth', \"my_image\":{'type': 'path'}},\n",
    "    'sampler': {\n",
    "        'type': 'independent',\n",
    "        'sample_count': 256\n",
    "    },\n",
    "    \"light\": {\"type\": \"constant\"},\n",
    "    \"sensor\": {\n",
    "        \"type\": \"perspective\",\n",
    "        \"to_world\": mi.ScalarTransform4f.look_at(\n",
    "            origin=[0, 7, 3], target=[0, 0, 0], up=[0, 0, 1]\n",
    "        ),\n",
    "    },\n",
    "    \"cylinder\": mesh,\n",
    "})\n",
    "img = mi.render(scene)\n",
    "depth = img.numpy()[:,:,-1]\n",
    "img_rgb = img.numpy()[:,:,:3]\n",
    "depth = 255 * depth / depth.max()\n",
    "print(img.shape)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb/img_rgb.max());\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KRT(fov=np.pi/3, HW=[400,400], cam_origin=None, target=None):\n",
    "\t\"\"\" Compute K matrix and camera pose from mitsuba3 scene. Returns torch.tensor K (3x3), and RT [4x4]\"\"\"\n",
    "\tH, W = HW \n",
    "\tfx = W / (2 * np.tan(fov/2))\n",
    "\tfy = fx\n",
    "\tcx, cy = W/2, H/2\n",
    "\tK = torch.tensor([[fx, 0.0, cx], [0.0, fy, cy], [0.0, 0.0, 1.0]]).float().cuda()\n",
    "\t# RT = torch.from_numpy(params['sensor.to_world'].matrix.numpy()).float().cuda()[0]\n",
    "\treturn K\n",
    "\n",
    "def pc_from_depth(depthmap, K, cam2world):\n",
    "    \"\"\" Compute point cloud from depthmap and K matrix \n",
    "    Args:\n",
    "\t\tdepthmap (torch.tensor) M,N\n",
    "\t\tK (torch.tensor) [3,3]\n",
    "\t\tcam2world (torch.tensor) [4,4] pose matrix that goes from camera to world \n",
    "    \"\"\"\n",
    "    fx, fy, cx, cy = K[0,0], K[1,1], K[0,2], K[1,2]\n",
    "    y, x = depthmap.shape[:2]\n",
    "    v, u = torch.meshgrid(torch.arange(y).cuda(), torch.arange(x).cuda(), indexing='ij')\n",
    "    X = (u - cx) * depthmap / fx \n",
    "    Y = (v - cy) * depthmap / fy\n",
    "    Z = depthmap\n",
    "    idx = depthmap > 0\n",
    "    ## Taking the optical pose transformation into account.\n",
    "    ## This whole part is kinda sus, but seems to be matching GT \n",
    "    points = torch.stack([X[idx], -Y[idx], -Z[idx]], dim=-1).reshape(-1,3)\n",
    "    points = points@cam2world[:3,:3].T + cam2world[:3, 3:].T\n",
    "    # R_z_90 = torch.tensor([[0.0, 1.0, 0.0], [-1.0, 0.0, 0.0], [0.0, 0.0, 1.0]]).cuda()\n",
    "    # # points = points @ R_z_90.T\n",
    "    return points\n",
    "    \n",
    "K = get_KRT()\n",
    "depthmap = render_depth(scene)\n",
    "points = pc_from_depth(depthmap, K, RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import matplotlib.pyplot as plt\n",
    "import mitsuba as mi \n",
    "import os \n",
    "from pyrender.platforms.osmesa import OSMesaPlatform\n",
    "pyrender.platform = OSMesaPlatform(400,400)\n",
    "\n",
    "\n",
    "mesh = pyrender.Mesh.from_trimesh(capped_cylinder)\n",
    "# c2w =mi.Transform4f.look_at(origin=[5,5,0], target=[0,0,0], up=[0,1,0]).matrix.numpy()[0]\n",
    "print(c2w)\n",
    "\n",
    "\n",
    "scene = pyrender.Scene()\n",
    "scene.add(mesh)\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.0)\n",
    "s = np.sqrt(2)/2\n",
    "camera_pose = np.array([\n",
    "    [0.0, -s,   s,   3],\n",
    "    [1.0,  0.0, 0.0, 0.0],\n",
    "    [0.0,  s,   s,   3.5],\n",
    "    [0.0,  0.0, 0.0, 1.0]])\n",
    "\n",
    "camera_pose = c2w\n",
    "scene.add(camera, pose=camera_pose)\n",
    "light = pyrender.SpotLight(color=np.ones(3), intensity=0.5,\n",
    "                            innerConeAngle=np.pi/16.0,\n",
    "                            outerConeAngle=np.pi/6.0)\n",
    "scene.add(light, pose=camera_pose)\n",
    "\n",
    "r = pyrender.OffscreenRenderer(400,400)\n",
    "color, depth = r.render(scene)\n",
    "plt.figure()\n",
    "plt.imshow(depth, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pc_from_depth(torch.from_numpy(depth).float().cuda(), K, torch.tensor(camera_pose).float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Generate some random 3D data points\n",
    "np.random.seed(0)\n",
    "points_np = pc.cpu().numpy()\n",
    "x, y, z = points_np[:,0], points_np[:,1], points_np[:,2]\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        color=z,                # Set color to the z values\n",
    "        colorscale='Viridis',   # Choose a colorscale\n",
    "        opacity=1.0\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X Axis',\n",
    "        yaxis_title='Y Axis',\n",
    "        zaxis_title='Z Axis'\n",
    "    ),\n",
    "    title='3D Point Cloud',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w =mi.Transform4f.look_at(origin=[3,0,3.5], target=[3.7071,0,4.2071], up=[-0.7071, 0, 0.7071]).matrix.numpy()[0]\n",
    "\n",
    "\n",
    "## To create camera pose with mitsuba for pyrender, have to use this weird look_at logic. that instead of looking at the origin, you look in the opposite direction. \n",
    "## Unsure how to convert this to mitsuba? \n",
    "c2w =mi.Transform4f.look_at(origin=[5,5,5], target=[5.5,5.5,5.5], up=[0, 0, 1.0]).matrix.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
