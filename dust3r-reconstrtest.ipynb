{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"dust3r\"))\n",
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "\n",
    "\n",
    "def save_dust3r_outs(focals, poses, pts3d, savepath):\n",
    "    \"\"\" Code to save output of dust3r after global alignment into a dictionary\n",
    "    Args: \n",
    "        focals (torch.Tensor): Optimized Focal length of the N cameras [N,1]\n",
    "        poses (torch.Tensor): Optimized Camera Poses [N,4,4]\n",
    "        pts3d list of (torch.Tensor): Point clouds as seen from each camera. \n",
    "    Returns:\n",
    "        None\n",
    "        saves a .pth file, can be loaded using torch.load()\n",
    "    \"\"\"\n",
    "    out_dict = {}\n",
    "    pts3d = [pts.cpu().detach() for pts in pts3d]\n",
    "    out_dict[\"focals\"] = focals.cpu().detach()\n",
    "    out_dict[\"poses\"] = poses.cpu().detach()\n",
    "    out_dict[\"pts3d\"] = pts3d\n",
    "    os.makedirs(os.path.dirname(savepath), exist_ok=True)\n",
    "    torch.save(out_dict, savepath)\n",
    "    print(f\"Saved Dust3r outputs to {savepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "batch_size = 1\n",
    "schedule = \"cosine\"\n",
    "lr = 0.01\n",
    "niter = 300\n",
    "\n",
    "model_name = \"checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)\n",
    "# load_images can take a list of images or a directory\n",
    "# images = load_images([\"croco/assets/Chateau1.png\", \"croco/assets/Chateau2.png\"], size=512)\n",
    "imdir = Path(\"data\") / \"barrelddt1\"\n",
    "outdir = Path(\"results\") / f\"{imdir.name}-reconstr\"\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "images = load_images(str(imdir), size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = make_pairs(images, scene_graph=\"complete\", prefilter=None, symmetrize=True)\n",
    "output = inference(pairs, model, device, batch_size=batch_size)\n",
    "\n",
    "# at this stage, you have the raw dust3r predictions\n",
    "view1, pred1 = output[\"view1\"], output[\"pred1\"]\n",
    "view2, pred2 = output[\"view2\"], output[\"pred2\"]\n",
    "# here, view1, pred1, view2, pred2 are dicts of lists of len(2)\n",
    "#  -> because we symmetrize we have (im1, im2) and (im2, im1) pairs\n",
    "# in each view you have:\n",
    "# an integer image identifier: view1[\"idx\"] and view2[\"idx\"]\n",
    "# the img: view1[\"img\"] and view2[\"img\"]\n",
    "# the image shape: view1[\"true_shape\"] and view2[\"true_shape\"]\n",
    "# an instance string output by the dataloader: view1[\"instance\"] and view2[\"instance\"]\n",
    "# pred1 and pred2 contains the confidence values: pred1[\"conf\"] and pred2[\"conf\"]\n",
    "# pred1 contains 3D points for view1[\"img\"] in view1[\"img\"] space: pred1[\"pts3d\"]\n",
    "# pred2 contains 3D points for view2[\"img\"] in view1[\"img\"] space: pred2[\"pts3d_in_other_view\"]\n",
    "\n",
    "# next we\"ll use the global_aligner to align the predictions\n",
    "# depending on your task, you may be fine with the raw output and not need it\n",
    "# with only two input images, you could use GlobalAlignerMode.PairViewer: it would just convert the output\n",
    "# if using GlobalAlignerMode.PairViewer, no need to run compute_global_alignment\n",
    "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
    "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)\n",
    "\n",
    "# retrieve useful values from scene:\n",
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "save_dust3r_outs(focals, poses, pts3d, savepath=outdir / \"dust3r_out.pth\")\n",
    "confidence_masks = scene.get_masks()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barrels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
