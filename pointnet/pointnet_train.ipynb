{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pointnet_utils import PointNetEncoder, feature_transform_reguliarzer\n",
    "\n",
    "\n",
    "## Write a Dataset Class to generate Cylinder Dataset, with different poses and augmentations. \n",
    "\n",
    "\n",
    "\n",
    "class BarrelNet(nn.Module):\n",
    "    def __init__(self, k=40, normal_channel=True):\n",
    "        super(BarrelNet, self).__init__()\n",
    "        if normal_channel:\n",
    "            channel = 6\n",
    "        else:\n",
    "            channel = 3\n",
    "        self.feat_normal = PointNetEncoder(global_feat=True, use_Tnet=False, channel=channel)\n",
    "        self.feat_radius = PointNetEncoder(global_feat=True, use_Tnet=True, channel=channel)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xn, _, _ = self.feat_normal(x)\n",
    "        xr, _, _ = self.feat_radius(x)\n",
    "        x = (xn + xr)/2# in future make it (xn + xr)/2\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        radius = F.sigmoid(x[:,-1])        \n",
    "        normal = torch.concatenate([F.tanh(x[:,:2]), F.sigmoid(x[:,2:3])], dim=1)\n",
    "        normal = normal / torch.linalg.norm(normal, dim=-1, keepdim=True)\n",
    "        return radius, normal \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "def create_capped_cylinder(radius, height, sections=32):\n",
    "    \"\"\"\n",
    "    Create a capped cylinder using trimesh.\n",
    "    \n",
    "    Args:\n",
    "        radius (float): Radius of the cylinder.\n",
    "        height (float): Height of the cylinder.\n",
    "        sections (int): Number of sections for the cylinder's roundness.\n",
    "        \n",
    "    Returns:\n",
    "        trimesh.Trimesh: A capped cylinder mesh.\n",
    "    \"\"\"\n",
    "    # Create the capped cylinder with cap=True\n",
    "    capped_cylinder = trimesh.creation.cylinder(radius=radius, height=height, sections=sections, cap=True)\n",
    "    \n",
    "    return capped_cylinder\n",
    "\n",
    "# Example usage\n",
    "radius = 1.0\n",
    "height = 4.0\n",
    "capped_cylinder = create_capped_cylinder(radius, height)\n",
    "\n",
    "# Visualization (optional)\n",
    "capped_cylinder.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import roma\n",
    "from data import generate_cylinder_pts, prepare_point_cloud, normalize_pc, CylinderData\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "    \n",
    "train_data = CylinderData(num_poses=5000)\n",
    "test_data = CylinderData(num_poses=1000)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "pointnet = BarrelNet(k=4, normal_channel=False).cuda()\n",
    "pointnet.train()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(pointnet.parameters(), lr=0.00005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.9)\n",
    "\n",
    "def compute_loss(sample, radius_pred, axis_pred, use_radius_loss=False, use_axis_loss=True):\n",
    "    \"\"\" Compute loss on the predictions of pointnet \"\"\"\n",
    "    assert use_axis_loss or use_radius_loss, \"Atleast one of the losses should be used\"\n",
    "    loss_axis = (1 - F.cosine_similarity(sample['axis_vec'], axis_pred, dim=1)).mean()\n",
    "    loss_radius = F.mse_loss(radius_pred, sample['radius_gt'] / sample['scale_gt'])\n",
    "    loss = 0.0 \n",
    "    if use_radius_loss:\n",
    "        loss = loss + loss_radius\n",
    "    if use_axis_loss:\n",
    "        loss = loss + loss_axis\n",
    "    return loss\n",
    "\n",
    "def train(model, train_loader, optimizer, scheduler, num_epochs=10000, save_epoch=1000, save_dir='weights/r0'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for sample in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            radius_pred, axis_pred = model(sample['pts'])\n",
    "            loss = compute_loss(sample, radius_pred, axis_pred, use_radius_loss=False, use_axis_loss=True)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Step the scheduler at the end of each epoch\n",
    "        scheduler.step()\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}, LR: {scheduler.get_last_lr()[0]}')\n",
    "\n",
    "        if epoch % save_epoch == 0:\n",
    "            torch.save(pointnet.state_dict(), os.path.join(save_dir, f'pointnet_iter{epoch}.pth'))\n",
    "\n",
    "train(pointnet, train_loader, optimizer, scheduler)\n",
    "torch.save(pointnet.state_dict(), 'weights/pointnet.pth')\n",
    "\n",
    "# # Example usage\n",
    "\n",
    "# points = generate_cylinder_pts(1.0, 1.0)\n",
    "# axis = torch.tensor([0.0, 0.0, 1.0])\n",
    "# points_valid, radius, burial_offset = prepare_point_cloud(points, axis)\n",
    "# pts, scale = normalize_pc(points_valid)\n",
    "# point_cloud_np = points.cpu().numpy()\n",
    "# point_cloud_rotated_np = points_valid.cpu().numpy()\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(121, projection='3d')\n",
    "# ax1.scatter(point_cloud_np[:, 0], point_cloud_np[:, 1], point_cloud_np[:, 2], s=1)\n",
    "# ax1.set_title(\"Original Point Cloud\")\n",
    "\n",
    "# ax2 = fig.add_subplot(122, projection='3d')\n",
    "# ax2.scatter(point_cloud_rotated_np[:, 0], point_cloud_rotated_np[:, 1], point_cloud_rotated_np[:, 2], s=1)\n",
    "# ax2.set_title(\"Rotated Point Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 253.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9999985694885254\n",
      "Worst Accuracy: 0.0026373863220214844\n",
      "Average Accuracy: 0.9705951552689075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    running_acc_axis = 0.0\n",
    "    accs_axis = []\n",
    "    criterion_cosine = nn.CosineSimilarity(dim=1)\n",
    "    for sample in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            radius_pred, axis_pred = model(sample['pts'])\n",
    "            radius_pred = radius_pred * sample['scale_gt'].cuda()\n",
    "            acc_axis = (1 + criterion_cosine(sample['axis_vec'], axis_pred).mean())/2\n",
    "            running_acc_axis += acc_axis.item()\n",
    "            accs_axis.append(acc_axis)\n",
    "    accs = torch.tensor(accs_axis)\n",
    "    print(f\"Best Accuracy: {torch.max(accs)}\")\n",
    "    print(f\"Worst Accuracy: {torch.min(accs)}\")\n",
    "    print(f'Average Accuracy: {running_acc_axis / len(test_loader)}')\n",
    "\n",
    "\n",
    "test(pointnet, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
